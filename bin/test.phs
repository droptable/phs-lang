new foo.bar;
new bar.baz(1,2,3);
new foo::bar::baz.zzz();
new (foo~'bar').baz();
new foo~bar();
new +foo();

__end__

module phs;

use std::io;
use std::ctype;

require 'glob.phs';

/** ascii tokens */
enum {
  T_ASSIGN = 61,   // '='
  T_LT = 60,       // '<'
  T_GT = 62,       // '>'
  T_PLUS = 43,     // '+'
  T_MINUS = 45,    // '-'
  T_DIV = 47,      // '/'
  T_MUL = 42,      // '*'
  T_MOD = 37,      // '%'
  T_BIT_NOT = 126, // '~'
  T_BIT_OR = 124,  // '|'
  T_BIT_AND = 38,  // '&'
  T_BIT_XOR = 94,  // '^'
  T_LPAREN = 40,   // '('
  T_RPAREN = 41,   // ')'
  T_LBRACKET = 91, // '['
  T_RBRACKET = 93, // ']'
  T_LBRACE = 123,  // '{'
  T_RBRACE = 125,  // '}'
  T_DOT = 46,      // '.'
  T_SEMI = 59,     // ';'
  T_COMMA = 44,    // ','
  T_AT = 64,       // '@'
  T_QM = 63,       // '?'
  T_EXCL = 33,     // '!'
  T_DDOT = 58,     // ':'
  T_EOF  = 0       // end of file
};

/**
 * lexer class
 * produces tokens for a given input-string
 */
class Lexer {
  private {
    // context
    let ctx;
    
    // input
    let data;
    
    // name of current file (not relevant)
    let file;
    
    // line and column
    let line, coln;
    
    // token queue
    let queue = [];
    
    // track new-lines after a '@'
    let tnl = false;
    
    // eof-indicator and cached eof-token
    let eof, eof_token;
    
    // lexer-pattern
    static re = io::get('lexer.re') as regexp;
  }
  
  /**
   * constructor
   * 
   * @param Context ctx
   * @param string data
   * @param string file
   */
  new (Context this.ctx, this.data, this.file) {}
  
  /**
   * error handler
   * 
   * @param mixed ...
   */
  fn error(...args) {
    let lvl = args.shift();
    let msg = args.shift();
    let loc = new Location(file, new Position(line, coln));
    
    ctx.verror_at(loc, COM_LEX, lvl, msg, args);
  }
  
  /**
   * returns the next token
   * 
   * @return Token
   */
  fn next() {
    if (queue.size())
      return queue.shift();
    
    return scan();
  }
  
  /**
   * peeks a token
   * 
   * @return Token
   */
  fn peek() {
    if (queue.size())
      return queue[0];
    
    let tok = scan();
    push(tok);
    
    return tok;
  }
  
  /**
   * pushes a token onto the queue
   * 
   * @param Token tok
   */
  fn push(Token tok) {
    queue.push(tok);
  }
  
  /**
   * skips a token
   */
  fn skip() {
    if (queue.size())
      queue.shift();
    else
      scan();
  }
  
  protected {
    /**
     * scans the given string for new-lines and adjusts $line and $coln
     * 
     * @param  string $sub
     * @param  int    $len
     */
    fn adjust_line_coln(sub, len) {
      sub = tocstr(sub);
      if (len == 0) len = strlen(sub);
      
      for (let idx = 0; idx < len; ++idx) {
        let cur = sub[idx];
        
        if (cur == '\n') {
          line += 1;
          coln = 1;
        } else
          coln += 1;
      }
    }
    
    /**
     * like adjust_line_coln() but stops on the first non-whitespace character
     * 
     * @param  string sub
     * @param  int    len
     */
    fn adjust_line_coln_beg(sub, len) {
      sub = tocstr(sub);
      if (len == 0) len = strlen(sub);
      
      for (let idx = 0; idx < len; ++idx) {
        let cur = sub[idx];
        
        // stop on non-whitespace
        if (!ctype::space(cur)) break;
        
        if (cur == '\n') {
          line += 1;
          coln = 1;
        } else
          coln += 1;
      }
    }
    
    /**
     * like adjust_line_coln() but skips whitespace characters at the beginning.
     * counterpart of adjust_line_coln_beg()
     * 
     * @param  string sub
     * @param  int    len
     */
    fn adjust_line_coln_end(sub, len) {
      let beg = false;
      
      sub = tocstr(sub);
      if (len == 0) len = strlen(sub);
      
      for (let idx = 0; idx < len; ++idx) {
        let cur = sub[idx];
        
        // skip whitespace at the beginning
        if (!beg && ctype::space(cur))
          continue;
        
        beg = true;
          
        if (cur == '\n') {
          line += 1;
          coln = 1;
        } else
          coln += 1;
      }
    }
    
    /**
     * scans a token
     * 
     * @return Token
     */
    fn scan() {        
      if (eof == true || ends()) {
        _seteof:
        
        // if EOF was not set before
        if (eof != true) {
          // produce one more TOK_SEMI
          eof = true;
          
          let tok = new_token(T_SEMI, ';', true);
          tok.implicit = true;
          return tok;
        }
       
        // generate EOF token to save memory if ->scan() gets called again
        if (!eof_token)
          eof_token = new_token(T_EOF, '<end of file>', true);
        
        return eof_token;
      }
      
      let tok = null;
      
      // loop used to avoid recursion if tokens get skipped (comments)
      for {  
        let m;
                
        // track new lines?
        if (tnl == true) {
          // test of a new-line can be scanned
          if (/^\h*\r?(\n)/.match(data)) {
            tnl = false;
            goto _prdtok;
          }
        } 
           
        if (!(m = re.match(data))) {
          // the scanner-pattern could not match anything
          // in this state we can not produce tokens (anymore)
          eof = true;
          adjust_line_coln_beg(data, 0);
          error(ERR_ABORT, 'invalid input');
          goto _seteof;
        }
        
        // start analizing
        _prdtok:
        
        // "raw" and "sub" matched data
        // raw: can contain whitespace at the beginning
        // sub: the relevant data
        let [ raw, sub ] = m.cstrs();
        let len = strlen(raw);
        
        // remove match from data
        data = data.substr(len);
        
        // get correct starting line/coln
        adjust_line_coln_beg(raw, len);
        
        // save start line/coln
        let pos = new Position(line, coln);
        
        // update end line/coln
        adjust_line_coln_end(sub, 0);
        
        // comments
        if (sub[0] == '#' || substr(sub, 0, 2) in [ '/*', '//' ]) {
          // handle <eof> if the comment was at the end of our input
          if (ends()) goto _seteof;
          continue; // continue otherwise
        }
        
        // if we scanned a string-literal: concat following strings
        // "foo" "bar" -> "foobar"
        if (sub[0] == '"') {
          sub = scan_concat(substr(sub, 1, -1));
          tok = new_token(T_STRING, sub);
        } elsif (sub[0] == "'") {
          // strings can be in single-quotes too.
          // note: concat only applies to double-quoted strings
          sub = substr(sub, 1, -1);
          tok = new_token(T_STRING, sub);
        } else {
          // analyze match
          tok = analyze(sub);
          assert tok != null : "analyze() failed";
          
          if (tok.type == T_SEMI)
            tok.implicit = false;
          // track new lines if the current token was a '@'
          elsif (tok.type == T_AT)
            tnl = true;
        }
        
        break;
      }
      
      assert tok != null : "invalid scan()";
      
      tok.raw = raw;
      tok.loc = new Location(file, pos);
      
      return tok;
    }

    /** 
     * scans a string-concat token
     * "foo" "bar" -> "foobar"
     * 
     * @param  string str
     * @return string
     */
    fn scan_concat(str) {
      static re = /^[\h\v]*["]([^\\\\"]+|[\\\\].)*["]/;
      
      for {
        let m;
        
        if (!(m = re.match(data)))
          break;
        
        let [ raw, sub ] = m.cstrs();
        let len = strlen(raw);
        str ~= sub;
        
        // update line and coln
        adjust_line_coln(raw, len);
        
        // remove scan from data
        data = data.substr(len);
      }
      
      return str;
    }
    
    /**
     * scans a regex
     * 
     * @return Token
     */
    fn scan_regexp(Token div) {  
      assert div.type == T_DIV : "invalid start of regexp";
      
      let reg = '/';
      let len = data.len();
      let idx = 0;    
      let esc = false;
      let mrk = false;
      let end = false;
      
      // copy $line and $coln to local vars
      let line = this.line;
      let coln = this.coln;
      
      while (idx < len) {
        let cur = data.char_at(idx++);
        
        // everything has an end :-)
        if (cur == '/' && !esc && !mrk) {
          end = true;
          coln += 1;
          break;
        }
        
        if (cur == '[' && !esc && !mrk)
          mrk = true; // in brackets now
        else {
          if (cur == ']' && !esc)
            mrk = false; // end of brackets
          elsif (cur == '\\') {
            esc = true; // in escape-sequence
            continue;
          }
        }
        
        // we do not compile the regex here, so just append the escape-char
        if (esc) reg ~= '\\';
        
        // we can not update the members $line and $coln directly,
        // because we don't know if the regex is valid
        if (cur == "\n") {
          line += 1;
          coln = 1;
        } else
          coln += 1;
        
        reg ~= cur;
        esc = false;
      }
      
      // do not handle it as regex
      if (!end) {
        error(ERR_WARN, 'a regular expression was expected but could not be scanned');
        // push a T_INVL token
        push(new_token(T_INVL, '<invalid>', true));
      } else {
        reg ~= '/';
        
        // flags
        _flags: for (; idx < len; ++idx) {
          cur = data.char_at(idx);
          
          switch (cur) {
            case 'i':
            case 'm':
            case 's':
            case 'A':
            case 'D':
            case 'S':
            case 'U':
            case 'X':
            case 'J':
            case 'u':
            case 'g':
              reg ~= cur;
              break;
            
            default:
              break _flags;
          }
          
          coln += 1;
        }
        
        // update $data, $line and $coln
        data = data.substr(idx);
        this.line = line;
        this.coln = coln;
        
        // construct token
        let tok = new_token(T_REGEXP, reg, false);
        tok.loc = div.loc;
        
        // push the token to the queue
        push(tok);
      }
    }
    
    /**
     * analyzes a scanned value and returns it as a token
     * 
     * @param  string  sub
     * @return Token
     */
    fn analyze(sub) {
      static re_dnum = /^(\.\d+|\d+\.\d*)/;
      static re_lnum = /^(\d+)([a-zA-Z_\x7f-\xff][a-zA-Z0-9_\x7f-\xff]*)?/;
      static re_base = /^(?:0[xX][0-9A-Fa-f]+|0[0-7]+|0[bB][01]+)$/;
      
      static eq_err = "'===' or '!==' found, used '==' or '!=' instead";
      
      let tok = null;
      let m;
      
      if (re_dnum.test(sub))
        // double
        tok = new_token(T_DNUM, sub);
      elsif ((m = re_lnum.match(sub))) {
        // integer (with optional suffix)
        let tid = m.len() > 2 ? T_SNUM : T_LNUM; 
        tok = new_token(tid, m[1]);
        tok.suffix = tid == T_SNUM ? m[2] : null;
      } elsif (re_base.test(sub)) {
        tok = new_token(T_LNUM, sub);
        tok.suffix = null;
      } else {
        // warn about '===' and '!=='
        if (sub == '===' || sub == '!==')
          error(ERR_WARN, eq_err);
        
        if (tok_table.has(sub))       
          // lookup token-table and check if the token is separator/operator  
          tok = new_token(tok_table.get(sub), sub);
        elsif (tok_rids.has(sub))
          // check if the token is a keyword (rid -> reserved identifier)
          tok = new_token(tok_rids.get(sub), sub); 
        else
          // otherwise the token must be a name
          tok = new_token(T_IDENT, sub);
      }
      
      return tok;
    }
    
    /**
     * creates a new token
     * 
     * @param  int type
     * @param  string value
     * @return Token
     */
    fn new_token(type, value, genloc = false) {
      let tok = new Token(type, value);
      
      if (genloc == true)
        tok.loc = new Location(file, new Position(line, coln));
      
      return tok;
    }
    
    /**
     * checks if the source can not produce more tokens
     * 
     * @return bool
     */
    fn ends() {
      static re_all = /^[\h\v]*$/;
      static re_nnl = /^[\h]*$/;
      
      // if $tnl (track new lines) is true: use \h, else: use \h\v
      return (tnl ? re_nnl : re_all).test(data);
    }
  }
  
  /* ------------------------------------ */
  
  private static {
    const tok_rids = {   
      fn: T_FN,
      let: T_LET,
      use: T_USE,
      enum: T_ENUM,
      class: T_CLASS,
      trait: T_TRAIT,
      iface: T_IFACE,
      module: T_MODULE,
      require: T_REQUIRE,

      true: T_TRUE,
      false: T_FALSE,
      null: T_NULL,
      this: T_THIS,
      super: T_SUPER,

      get: T_GET,
      set: T_SET,

      do: T_DO,
      if: T_IF,
      elsif: T_ELSIF,
      else: T_ELSE,
      for: T_FOR,
      try: T_TRY,
      goto: T_GOTO,
      break: T_BREAK,
      continue: T_CONTINUE,
      throw: T_THROW,
      catch: T_CATCH,
      finally: T_FINALLY,
      while: T_WHILE,
      assert: T_ASSERT,
      switch: T_SWITCH,
      case: T_CASE,
      "default": T_DEFAULT,
      return: T_RETURN,

      const: T_CONST,
      final: T_FINAL,
      global: T_GLOBAL,
      static: T_STATIC,
      extern: T_EXTERN,
      public: T_PUBLIC,
      private: T_PRIVATE,
      protected: T_PROTECTED,
      
      // this tokens are '''shortcuts''' for the corresponding attributes
      __sealed__: T_SEALED, // @ sealed fn ...
      __inline__: T_INLINE, // @ inline fn ...
      
      __php__: T_PHP,
      __test__: T_TEST,
      
      __file__: T_CFILE,
      __line__: T_CLINE,
      __coln__: T_CCOLN,
      
      __fn__: T_CFN,
      __class__: T_CCLASS,
      __method__: T_CMETHOD,
      __module__: T_CMODULE,
      
      "yield": T_YIELD,
      "new": T_NEW,
      "del": T_DEL,
      "as": T_AS,
      "is": T_IS,
      "isnt": T_ISNT,
      "in": T_IN,
      
      int: T_TINT,
      integer: T_TINT,
      bool: T_TBOOL,
      boolean: T_TBOOL,
      float: T_TFLOAT,
      double: T_TFLOAT,
      string: T_TSTRING,
      regexp: T_TREGEXP
    };
    
    // some tokens are ascii-tokens, see comment at the top of this file
    const tok_table = {  
      // this is aspecial token used for new-lines
      "\n": T_NL,
       
      '=': T_ASSIGN,
      '+=': T_APLUS,
      '-=': T_AMINUS,
      '*=': T_AMUL,
      '**=': T_APOW,
      '/=': T_ADIV,
      '%=': T_AMOD,
      '~=': T_ABIT_NOT,
      '|=': T_ABIT_OR,
      '&=': T_ABIT_AND,
      '^=': T_ABIT_XOR,
      '||=': T_ABOOL_OR,
      '&&=': T_ABOOL_AND,
      '^^=': T_ABOOL_XOR,
      '<<=': T_ASHIFT_L,
      '>>=': T_ASHIFT_R,
      
      '==': T_EQ,
      '!=': T_NEQ,
      '===': T_EQ,
      '!==': T_NEQ,
      
      '<': T_LT,
      '>': T_GT,
      '<=': T_LTE,
      '>=': T_GTE,
      
      '>>': T_SR,
      '<<': T_SL,
      
      '+': T_PLUS,
      '-': T_MINUS,
      '/': T_DIV,
      '*': T_MUL,
      '%': T_MOD,
      '**': T_POW,
      
      '~': T_BIT_NOT,
      '|': T_BIT_OR,
      '&': T_BIT_AND,
      '^': T_BIT_XOR,
      
      '||': T_BOOL_OR,
      '&&': T_BOOL_AND,
      '^^': T_BOOL_XOR, 
      
      '++': T_INC,
      '--': T_DEC,
      
      '(': T_LPAREN,
      ')': T_RPAREN,
      '[': T_LBRACKET,
      ']': T_RBRACKET,    
      '{': T_LBRACE,
      '}': T_RBRACE,
      
      '.': T_DOT,
      '..': T_RANGE,
      '...': T_REST,
      
      ';': T_SEMI,
      ',': T_COMMA,
      
      '@': T_AT,
      '?': T_QM,
      '!': T_EXCL,
      ':': T_DDOT,
      '::': T_DDDOT,
      '=>': T_ARR,
      // '!.': T_BANG
    };
  }
}
